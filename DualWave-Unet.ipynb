{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":118448,"databundleVersionId":14559231,"sourceType":"competition"},{"sourceId":10272840,"sourceType":"datasetVersion","datasetId":6318121,"isSourceIdPinned":true},{"sourceId":11848037,"sourceType":"datasetVersion","datasetId":7444432},{"sourceId":703941,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":523637,"modelId":537656},{"sourceId":712045,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":541020,"modelId":554209},{"sourceId":718124,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":546023,"modelId":559020}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ===============================================","metadata":{}},{"cell_type":"code","source":"#already\n!pip install SimpleITK\n!pip install monai\n!pip install einops\n!pip install progress_table\n!pip uninstall -y protobuf -q\n!pip install protobuf==5.26.1 -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:05:28.832476Z","iopub.execute_input":"2025-12-18T13:05:28.832665Z","iopub.status.idle":"2025-12-18T13:06:56.523589Z","shell.execute_reply.started":"2025-12-18T13:05:28.832649Z","shell.execute_reply":"2025-12-18T13:06:56.522678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport os\nimport numpy as np\nimport torch\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    print(f\"✅ Seed set to {seed}\")\n\n# --- THAY SEED ---\nCURRENT_SEED = 1\nseed_everything(CURRENT_SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:06:56.524732Z","iopub.execute_input":"2025-12-18T13:06:56.525032Z","iopub.status.idle":"2025-12-18T13:06:59.435144Z","shell.execute_reply.started":"2025-12-18T13:06:56.525004Z","shell.execute_reply":"2025-12-18T13:06:59.434299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:06:59.436916Z","iopub.execute_input":"2025-12-18T13:06:59.437218Z","iopub.status.idle":"2025-12-18T13:06:59.442040Z","shell.execute_reply.started":"2025-12-18T13:06:59.437194Z","shell.execute_reply":"2025-12-18T13:06:59.441285Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ===================================================================================================\n### Testing","metadata":{}},{"cell_type":"code","source":"import logging\nimport os\nfrom datetime import datetime\n\n#Lib for preprocess + train\nimport SimpleITK as sitk\nimport torch\nfrom sklearn.model_selection import KFold\nfrom torch.utils.data.dataset import Dataset\nimport argparse\nimport random\nimport pathlib\nimport time\nimport torch.backends.cudnn as cudnn\nimport torch.nn.parallel\nimport torch.optim\nimport torch.utils.data\nimport yaml\nfrom monai.data import decollate_batch\nfrom torch.autograd import Variable\nimport math\n\nimport os\nimport cv2\nfrom glob import glob\nimport numpy as np\nimport pandas as pd\nimport nibabel as nib\nfrom matplotlib import colors\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n\n#lib for model\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nfrom torch import optim\n\nimport wandb\n\n#for training\nfrom functools import partial\nfrom monai.metrics import DiceMetric\nfrom monai.inferers import sliding_window_inference\nfrom monai.transforms import (\n    SpatialCrop,\n    Activations,\n    AsDiscrete,\n    Compose,\n    EnsureType\n)\n\nfrom monai.losses import DiceLoss #Minh co can code lai ham loss khong?\nimport monai.transforms as transforms\nfrom monai.transforms import NormalizeIntensity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:06:59.442772Z","iopub.execute_input":"2025-12-18T13:06:59.443029Z","iopub.status.idle":"2025-12-18T13:07:38.335708Z","shell.execute_reply.started":"2025-12-18T13:06:59.443007Z","shell.execute_reply":"2025-12-18T13:07:38.335146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#đáng lẽ hai cái này là hai cái khác nhau nhưng vì ở đây mình dùng bộ data đã có sẵn traningdata nên trùng\n\nBRATS_TRAIN_FOLDERS = \"/kaggle/input/brats2021/BraTS_2021_TrainingData/BraTS_2021_TrainingData\"\nDATA_PATH = '/kaggle/input/brats2021/BraTS_2021_TrainingData'\nVALI_PATH = '/kaggle/input/brats2021/BraTS_2021_ValidationData/BraTS_2021_ValidationData'\n\nDATA_TYPES = ['t1', 't1ce', 't2', 'flair', 'seg']\nMASK_LABELS = ['Not Tumor', 'Non-Enhancing Tumor Core', 'Peritumoral Edema', 'GD-Enhancing Tumor']\nMASK_VALUES = [0, 1, 2, 4]\n#data_paths = {dt: sorted(glob(DATA_PATH + '/*/*.' + dt + '.nii')) for dt in DATA_TYPES}\n# data_paths = {dt: sorted(glob(DATA_PATH + '/**/*_{}.nii'.format(dt))) for dt in DATA_TYPES}\n# data_paths['seg'] = sorted(data_paths['seg'])\n# data_paths_train = {dt: sorted(glob(os.path.join(DATA_PATH, '**', f'*.{dt}.nii'), recursive=True)) for dt in DATA_TYPES}\n# data_paths_vali = {dt: sorted(glob(os.path.join(VALI_PATH, '**', f'*.{dt}.nii'), recursive=True)) for dt in DATA_TYPES}\n\n# # Merge train and validation paths for each data type\n# data_paths = {dt: data_paths_train[dt] + data_paths_vali[dt] for dt in DATA_TYPES}\n\n# data_paths['seg'] = sorted(data_paths['seg'])\n# for key, vals in data_paths.items():\n#     print('[TRAIN] Number of {} images: {}'.format(key,  len(vals)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:38.336472Z","iopub.execute_input":"2025-12-18T13:07:38.336689Z","iopub.status.idle":"2025-12-18T13:07:38.341089Z","shell.execute_reply.started":"2025-12-18T13:07:38.336671Z","shell.execute_reply":"2025-12-18T13:07:38.340356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#preprocessing function\n\"\"\"functions to correctly pad or crop non uniform sized MRI (before batching in the dataloader).\n\"\"\"\ndef get_brats_folder(on=\"train\"):\n    if on == \"train\":\n        return BRATS_TRAIN_FOLDERS\n    else:\n        return VALI_PATH\ndef pad_or_crop_image(image, seg=None, target_size=(128, 144, 144)):\n    c, z, y, x = image.shape\n    z_slice, y_slice, x_slice = [get_crop_slice(target, dim) for target, dim in zip(target_size, (z, y, x))]\n    image = image[:, z_slice, y_slice, x_slice]\n    if seg is not None:\n        seg = seg[:, z_slice, y_slice, x_slice]\n    todos = [get_left_right_idx_should_pad(size, dim) for size, dim in zip(target_size, [z, y, x])]\n    padlist = [(0, 0)]  # channel dim\n    for to_pad in todos:\n        if to_pad[0]:\n            padlist.append((to_pad[1], to_pad[2]))\n        else:\n            padlist.append((0, 0))\n    image = np.pad(image, padlist)\n    if seg is not None:\n        seg = np.pad(seg, padlist)\n        return image, seg\n    return image\n\ndef get_left_right_idx_should_pad(target_size, dim):\n    if dim >= target_size:\n        return [False]\n    elif dim < target_size:\n        pad_extent = target_size - dim\n        left = random.randint(0, pad_extent)\n        right = pad_extent - left\n        return True, left, right\n\ndef get_crop_slice(target_size, dim):\n    if dim > target_size:\n        crop_extent = dim - target_size\n        left = random.randint(0, crop_extent)\n        right = crop_extent - left\n        return slice(left, dim - right)\n    elif dim <= target_size:\n        return slice(0, dim)\ndef get_crop_slice2(target_size, dim):\n    if dim > target_size:\n        start = (dim - target_size) // 2\n        end = start + target_size\n        return slice(start, end)\n    elif dim <= target_size:\n        return slice(0, dim)\ndef pad_or_crop_image_label(image, seg=None, target_size=(128, 128, 128)):\n    c, z, y, x = image.shape\n    z_slice, y_slice, x_slice = [get_crop_slice2(target, dim) for target, dim in zip(target_size, (z, y, x))]\n    image = image[:, z_slice, y_slice, x_slice]\n    if seg is not None:\n        seg = seg[:, z_slice, y_slice, x_slice]\n    \n    # Pad nếu cần\n    # todos = [get_left_right_idx_should_pad(size, dim) for size, dim in zip(target_size, [z, y, x])]\n    # padlist = [(0, 0)]  # channel dim\n    # for to_pad in todos:\n    #     if to_pad[0]:\n    #         padlist.append((to_pad[1], to_pad[2]))\n    #     else:\n    #         padlist.append((0, 0))\n    \n    # # Pad ảnh để đạt được target_size\n    # image = np.pad(image, padlist)\n    if seg is not None:\n        # seg = np.pad(seg, padlist)\n        return image, seg\n    return image\n\n\ndef normalize(image):\n    \"\"\"Basic min max scaler.\n    \"\"\"\n    min_ = np.min(image)\n    max_ = np.max(image)\n    scale = max_ - min_\n    image = (image - min_) / scale\n    return image\n\ndef irm_min_max_preprocess(image, low_perc=1, high_perc=99):\n    \"\"\"Main pre-processing function used for the challenge (seems to work the best).\n\n    Remove outliers voxels first, then min-max scale.\n\n    Warnings\n    --------\n    This will not do it channel wise!!\n    \"\"\"\n\n    non_zeros = image > 0\n    low, high = np.percentile(image[non_zeros], [low_perc, high_perc])\n    image = np.clip(image, low, high)\n    image = normalize(image)\n    return image\n\ndef zscore_normalise(img):\n    # Đảm bảo rằng img có kiểu dữ liệu float\n    img = img.astype(np.float32)  # Nếu img là ndarray\n    # img = img.to(torch.float32)  # Nếu img là tensor\n    \n    slices = slice(None)\n    img[slices] = (img[slices] - np.mean(img[slices])) / np.std(img[slices])\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:38.342063Z","iopub.execute_input":"2025-12-18T13:07:38.342338Z","iopub.status.idle":"2025-12-18T13:07:38.418714Z","shell.execute_reply.started":"2025-12-18T13:07:38.342314Z","shell.execute_reply":"2025-12-18T13:07:38.418076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Brats(Dataset):\n    def __init__(self, patients_dir, benchmarking=False, training=True, data_aug=False,\n                 no_seg=False, normalisation=\"zscore\", normal=False):\n        super(Brats, self).__init__()\n        self.benchmarking = benchmarking\n        self.normalisation = normalisation\n        self.data_aug = data_aug\n        self.training = training\n        self.datas = []\n        self.validation = no_seg\n        self.normal = normal\n        self.patterns = [\".t1\", \".t1ce\", \".t2\", \".flair\"]\n        self.target_spacing = [1.0, 1.0, 1.0]\n        self.roi_size = [128, 128, 128]\n        if self.training:\n            self.transform = transforms.Compose([\n                transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.1, spatial_axis=0), #aug\n                transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.1, spatial_axis=1), #aug\n                transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.1, spatial_axis=2), #aug\n                # transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n                transforms.RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0), #aug\n                transforms.RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0), #aug\n            ])\n        else:\n            # Validation/Inference pipeline\n            self.transform = transforms.Compose([\n                transforms.CropForegroundd(\n                    keys=[\"image\", \"label\"],\n                    source_key=\"image\",\n                    k_divisible=self.roi_size,\n                )\n            ])\n        \n        if not no_seg:\n            self.patterns += [\".seg\"]\n        for patient_dir in patients_dir:\n            patient_id = patient_dir.name\n            # Construct paths for each modality\n            paths = [patient_dir / f\"{patient_id}{value}.nii\" for value in self.patterns]\n            \n            # Add patient data\n            patient = dict(\n                id=patient_id,\n                t1=paths[0], t1ce=paths[1], t2=paths[2], flair=paths[3],\n                seg=paths[4] if not no_seg else None\n            )\n            self.datas.append(patient)\n\n\n    \n        \n    def __getitem__(self, idx):\n        _patient = self.datas[idx]\n        \n        patient_image = {key: self.load_nii(_patient[key]) for key in _patient if key not in [\"id\", \"seg\"]} \n        #-> load t1 t1w t2 flair\n        if _patient[\"seg\"] is not None:\n            patient_label = self.load_nii(_patient[\"seg\"])\n            et = patient_label == 4 # ET (Enhancing Tumor) - label 4\n            et_present = 1 if np.sum(et) >= 1 else 0\n            tc = np.logical_or(patient_label == 4, patient_label == 1) #TC (Tumor Core) - label 1, 4\n            wt = np.logical_or(tc, patient_label == 2) # WT (Whole Tumor) label 1, 2, 4\n            patient_label = np.stack([et, tc, wt])\n        else:\n            patient_label = np.zeros(patient_image.shape)  # placeholders, not gonna use it\n            et_present = 0\n\n        if self.normal == False: \n            if self.normalisation == \"minmax\":\n                patient_image = {key: irm_min_max_preprocess(patient_image[key]) for key in patient_image}\n            elif self.normalisation == \"zscore\":\n                patient_image = {key: zscore_normalise(patient_image[key]) for key in patient_image}\n        else:\n            # patient_image = {key: zscore_normalise(patient_image[key]) for key in patient_image}\n            normalize_intensity = NormalizeIntensity(nonzero=True, channel_wise=True)\n            patient_image = {key: normalize_intensity(patient_image[key]) for key in patient_image}  # Chuẩn hóa cường độ cho mỗi ảnh\n\n        patient_image = np.stack([patient_image[key] for key in patient_image])\n\n        if self.training:\n            z_indexes, y_indexes, x_indexes = np.nonzero(np.sum(patient_image, axis=0) != 0)\n            zmin, ymin, xmin = [max(0, int(np.min(arr) - 1)) for arr in (z_indexes, y_indexes, x_indexes)]\n            zmax, ymax, xmax = [int(np.max(arr) + 1) for arr in (z_indexes, y_indexes, x_indexes)]\n            patient_image = patient_image[:, zmin:zmax, ymin:ymax, xmin:xmax]\n            patient_label = patient_label[:, zmin:zmax, ymin:ymax, xmin:xmax]              \n            patient_image, patient_label = pad_or_crop_image(patient_image, patient_label, target_size=(128, 128, 128))\n\n            if self.normal == True:\n                data_dict = {\n                    \"image\": patient_image,\n                    \"label\": patient_label,\n                }\n                transformed = self.transform(data_dict)\n    \n                patient_image = transformed[\"image\"]\n                patient_label = transformed[\"label\"]\n        else:\n            z_indexes, y_indexes, x_indexes = np.nonzero(np.sum(patient_image, axis=0) != 0)\n            zmin, ymin, xmin = [max(0, int(np.min(arr) - 1)) for arr in (z_indexes, y_indexes, x_indexes)]\n            zmax, ymax, xmax = [int(np.max(arr) + 1) for arr in (z_indexes, y_indexes, x_indexes)]\n            patient_image = patient_image[:, zmin:zmax, ymin:ymax, xmin:xmax]\n            patient_label = patient_label[:, zmin:zmax, ymin:ymax, xmin:xmax]  \n            patient_image, patient_label = pad_or_crop_image_label(patient_image, patient_label, target_size=(128, 128, 128))\n\n\n        # Tiến hành các bước tiếp theo với transformed\n        patient_image, patient_label = patient_image.astype(\"float16\"), patient_label.astype(\"bool\")\n        patient_image, patient_label = [torch.from_numpy(x) for x in [patient_image, patient_label]]\n\n        return dict(patient_id=_patient[\"id\"],\n                    image=patient_image, label=patient_label,\n                    seg_path=str(_patient[\"seg\"]) if self.training else str(_patient[\"t1\"]),\n                    crop_indexes=((zmin, zmax), (ymin, ymax), (xmin, xmax)),\n                    et_present=et_present,\n                    supervised=True,\n                    idx=idx,\n                    )\n\n    @staticmethod\n    def load_nii(path_folder):\n        return sitk.GetArrayFromImage(sitk.ReadImage(str(path_folder)))\n\n    def __len__(self):\n        return len(self.datas)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:38.419596Z","iopub.execute_input":"2025-12-18T13:07:38.420067Z","iopub.status.idle":"2025-12-18T13:07:38.439718Z","shell.execute_reply.started":"2025-12-18T13:07:38.420041Z","shell.execute_reply":"2025-12-18T13:07:38.439083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"##### \n\"\"\"\nShould check this\n\nGet full data\n\"\"\"\n\n\ndef get_datasets(seed, on=\"train\", fold_number=0, normalisation=\"zscore\", use_fold = False):\n    base_folder_train = pathlib.Path(get_brats_folder(on)).resolve()\n    base_folder_vali = pathlib.Path(get_brats_folder(\"a\")).resolve()\n    assert base_folder_train.exists()\n    patients_dir_train = sorted([x for x in base_folder_train.iterdir() if x.is_dir()])\n    patients_dir_vali = sorted([x for x in base_folder_vali.iterdir() if x.is_dir()])\n\n\n    if use_fold == True:\n        kfold = KFold(5, shuffle=True, random_state=seed)\n    \n        splits = list(kfold.split(patients_dir_train))\n        train_idx, test_idx = splits[fold_number]\n    \n    \n        train = [patients_dir_train[i] for i in train_idx]\n        test = [patients_dir_train[i] for i in test_idx]\n        train_dataset = Brats(train, training=True, normalisation=normalisation, normal = True)\n        test_dataset = Brats(test, training=False, benchmarking=True, normalisation=normalisation, normal = True)\n    else:\n        train_dataset = Brats(patients_dir_train, training=True, normalisation=normalisation, normal = True)\n        test_dataset = Brats(patients_dir_vali, training=False, benchmarking=True, normalisation=normalisation, normal = True)\n\n    return train_dataset, test_dataset\n\nfull_train_dataset, val_dataset = get_datasets(123, fold_number=0)\nprint(len(full_train_dataset), len(val_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:38.440480Z","iopub.execute_input":"2025-12-18T13:07:38.440738Z","iopub.status.idle":"2025-12-18T13:07:39.776985Z","shell.execute_reply.started":"2025-12-18T13:07:38.440716Z","shell.execute_reply":"2025-12-18T13:07:39.776301Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCreate loader for neural network\n\"\"\"\n\n\ntrain_loader = torch.utils.data.DataLoader(full_train_dataset, batch_size=1, shuffle=True,\n                                           num_workers=2, pin_memory=True, drop_last=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False,\n                                         pin_memory=True, num_workers=2)\n\nprint(\"Train dataset number of batch:\", len(train_loader))\nprint(\"Val dataset number of batch:\", len(val_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:39.779199Z","iopub.execute_input":"2025-12-18T13:07:39.779412Z","iopub.status.idle":"2025-12-18T13:07:39.784571Z","shell.execute_reply.started":"2025-12-18T13:07:39.779395Z","shell.execute_reply":"2025-12-18T13:07:39.783834Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nXem lại định dạng dữ liệu đầu vào của mô hình\n\n\"\"\"\n\nfor batch in train_loader:\n    # Assuming your input data is a 4D tensor (batch_size, channels, height, width)\n    \n    data_shape = batch['image'].shape\n    label_shape = batch['label'].shape\n    print(\"Data shape in the first batch:\", data_shape)\n    print(\"Label shape in the first batch:\", label_shape)\n    break  # Print only the first batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:39.785419Z","iopub.execute_input":"2025-12-18T13:07:39.785669Z","iopub.status.idle":"2025-12-18T13:07:43.166746Z","shell.execute_reply.started":"2025-12-18T13:07:39.785649Z","shell.execute_reply":"2025-12-18T13:07:43.166084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# label_colors = ['red','yellow', 'green']\n# color_values = {'red': (255, 0, 0, 255),  'yellow': (255, 255, 0, 255),'green': (0, 255, 0, 255)}\n\n# background_color = (0, 0, 0, 255)\n# i=0\n# # Get a single batch from the DataLoader\n# for batch in train_loader:\n\n#     print(batch['patient_id'])\n#     image_sample = batch['image']\n#     label_sample = batch['label']\n#     image_sample_np = image_sample.numpy()\n#     label_sample_np = label_sample.numpy()\n\n\n#     # Select the central slice along the z-axis (depth) for visualization\n#     z_slice =  image_sample_np.shape[2] // 2 +2 # between\n\n#     # Plot each channel of the image sample\n#     num_channels = image_sample_np.shape[1]\n#     fig, axes = plt.subplots(1, num_channels, figsize=(15, 5))\n\n#     for channel in range(num_channels):\n#         axes[channel].imshow(image_sample_np[0, channel, z_slice], cmap='gray')\n#         axes[channel].set_title(f\"Image Channel {channel + 1}\")\n\n\n#     plt.tight_layout()\n#     plt.show()\n\n#     # Plot each channel of the label sample (assuming 3 channels for one-hot encoded segmentation)\n#     num_channels_labels = label_sample_np.shape[1]\n#     fig, axes = plt.subplots(1, num_channels_labels, figsize=(15, 5))\n\n#     for channel in range(num_channels_labels):\n#         axes[channel].imshow(label_sample_np[0, channel, z_slice], cmap='gray')\n#         axes[channel].set_title(f\"Label Channel {channel + 1}\")\n\n\n#     plt.tight_layout()\n#     plt.show()\n\n\n\n#     image_sample_np = np.full((label_sample_np.shape[3], label_sample_np.shape[4], 4), background_color, dtype=np.uint8)\n#     # Combine the label channels with different colors\n#     num_channels_labels = label_sample_np.shape[1]\n#     for channel in range(num_channels_labels-1, -1, -1):\n#         label_channel = label_sample_np[0, channel, z_slice]\n\n#         # Overlay the label with a unique color\n#         label_color = label_colors[channel % len(label_colors)]\n#         color_value = color_values[label_color]\n\n#         # Create a mask for the current label channel\n#         label_mask = label_channel > 0\n\n#         # Apply the color with alpha channel to the corresponding pixels in the composite label\n#         image_sample_np[label_mask] = color_value\n\n#     # Plot the composite label image\n#     plt.figure(figsize=(10, 5))\n#     plt.imshow(image_sample_np)\n#     plt.title(\"Composite Label\")\n#     plt.show()\n#     i+=1\n#     if i == 10:\n#         break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:43.167878Z","iopub.execute_input":"2025-12-18T13:07:43.168113Z","iopub.status.idle":"2025-12-18T13:07:43.172630Z","shell.execute_reply.started":"2025-12-18T13:07:43.168089Z","shell.execute_reply":"2025-12-18T13:07:43.171986Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ===================================================================================================\n","metadata":{}},{"cell_type":"markdown","source":"## Set up model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nimport torch.nn.functional as F\nimport math \n\nfrom torch.autograd import Variable\nfrom einops import rearrange, repeat \nfrom einops.layers.torch import Rearrange\nimport einops\nimport numpy as np\n\n# from timm.models.layers import DropPath","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:43.173428Z","iopub.execute_input":"2025-12-18T13:07:43.173704Z","iopub.status.idle":"2025-12-18T13:07:43.225588Z","shell.execute_reply.started":"2025-12-18T13:07:43.173677Z","shell.execute_reply":"2025-12-18T13:07:43.225017Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Wavelet Blocks","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\n\ndef get_wav_3d(in_channels, pool=True):\n    # 3D Haar wavelet filters\n    s = 1 / np.sqrt(2)\n    harr_wav_L = s * np.ones((1, 2))\n    harr_wav_H = s * np.ones((1, 2))\n    harr_wav_H[0, 0] = -harr_wav_H[0, 0]\n\n    # 3D filter banks (2x2x2 kernels)\n    LLL = np.kron(np.kron(harr_wav_L, harr_wav_L), harr_wav_L).reshape(1, 1, 2, 2, 2)\n    LLH = np.kron(np.kron(harr_wav_L, harr_wav_L), harr_wav_H).reshape(1, 1, 2, 2, 2)\n    LHL = np.kron(np.kron(harr_wav_L, harr_wav_H), harr_wav_L).reshape(1, 1, 2, 2, 2)\n    LHH = np.kron(np.kron(harr_wav_L, harr_wav_H), harr_wav_H).reshape(1, 1, 2, 2, 2)\n    HLL = np.kron(np.kron(harr_wav_H, harr_wav_L), harr_wav_L).reshape(1, 1, 2, 2, 2)\n    HLH = np.kron(np.kron(harr_wav_H, harr_wav_L), harr_wav_H).reshape(1, 1, 2, 2, 2)\n    HHL = np.kron(np.kron(harr_wav_H, harr_wav_H), harr_wav_L).reshape(1, 1, 2, 2, 2)\n    HHH = np.kron(np.kron(harr_wav_H, harr_wav_H), harr_wav_H).reshape(1, 1, 2, 2, 2)\n\n    filters = [LLL, LLH, LHL, LHH, HLL, HLH, HHL, HHH]\n    filter_tensors = [torch.from_numpy(f).float() for f in filters]  # Shape: [1, 1, 2, 2, 2]\n\n    if pool:\n        net = nn.Conv3d\n    else:\n        net = nn.ConvTranspose3d\n\n    subbands = []\n    for f in filter_tensors:\n        conv = net(in_channels, in_channels, kernel_size=2, stride=2, padding=0, bias=False, groups=in_channels)\n        conv.weight.requires_grad = False\n        # More efficient expansion - using repeat_interleave for grouped convolution\n        f_expanded = f.repeat_interleave(in_channels, dim=0).view(in_channels, 1, 2, 2, 2)\n        conv.weight.data = f_expanded\n        subbands.append(conv)\n    \n    return subbands\n\nclass WavePool3D(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        self.LLL, self.LLH, self.LHL, self.LHH, self.HLL, self.HLH, self.HHL, self.HHH = get_wav_3d(in_channels, pool=True)\n\n    def forward(self, x):\n        return [self.LLL(x), self.LLH(x), self.LHL(x), self.LHH(x), self.HLL(x), self.HLH(x), self.HHL(x), self.HHH(x)]\n\nclass WaveUnpool3D(nn.Module):\n    def __init__(self, in_channels, option_unpool='sum'):\n        super().__init__()\n        self.in_channels = in_channels\n        self.option_unpool = option_unpool\n        self.LLL, self.LLH, self.LHL, self.LHH, self.HLL, self.HLH, self.HHL, self.HHH = get_wav_3d(in_channels, pool=False)\n\n    def forward(self, subbands, include_low=True):\n        # Unpack the list of subbands\n        LLL, LLH, LHL, LHH, HLL, HLH, HHL, HHH = subbands\n        if self.option_unpool == 'sum':\n            high_freq_sum = (self.LLH(LLH) + self.LHL(LHL) + self.LHH(LHH) + \n                             self.HLL(HLL) + self.HLH(HLH) + self.HHL(HHL) + \n                             self.HHH(HHH))\n            if include_low:\n                return self.LLL(LLL) + high_freq_sum\n            else:\n                return high_freq_sum\n                \n        elif self.option_unpool == 'cat':\n            if include_low:\n                return torch.cat([self.LLL(LLL), self.LLH(LLH), self.LHL(LHL), self.LHH(LHH),\n                              self.HLL(HLL), self.HLH(HLH), self.HHL(HHL), self.HHH(HHH)], dim=1)\n            else:\n                return torch.cat([self.LLH(LLH), self.LHL(LHL), self.LHH(LHH),\n                              self.HLL(HLL), self.HLH(HLH), self.HHL(HHL), self.HHH(HHH)], dim=1)\n        else:\n            raise NotImplementedError\n\n\nclass WaveletAttentionFusion(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        # Project high-frequency features to out_channels\n        self.high_freq_proj = nn.Conv3d(in_channels * 7, out_channels, kernel_size=1, bias=False)\n        # Attention mechanism for high-frequency features\n        self.attn = nn.Sequential(\n            nn.Conv3d(out_channels, out_channels, kernel_size=1, bias=False),\n            nn.InstanceNorm3d(out_channels),\n            nn.LeakyReLU(inplace=True),\n            nn.Conv3d(out_channels, 1, kernel_size=1),  # Spatial attention\n            nn.Sigmoid()\n        )\n        # Fuse main and attended high-frequency features\n        self.fuse = nn.Sequential(\n            nn.Conv3d(out_channels * 2, out_channels, kernel_size=1, bias=False),\n            nn.InstanceNorm3d(out_channels),\n            nn.LeakyReLU(inplace=True)\n        )\n\n    def forward(self, x, high_freq):\n        # high_freq: list of 7 tensors [B, in_channels, D, H, W]\n        high_freq_cat = torch.cat(high_freq, dim=1)  # [B, in_channels*7, D, H, W]\n        high_freq_feat = self.high_freq_proj(high_freq_cat)  # [B, out_channels, D, H, W]\n        attn_map = self.attn(high_freq_feat)  # [B, 1, D, H, W]\n        high_freq_attended = high_freq_feat * attn_map  # [B, out_channels, D, H, W]\n        fused = torch.cat([x, high_freq_attended], dim=1)  # [B, out_channels*2, D, H, W]\n        out = self.fuse(fused)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:43.226250Z","iopub.execute_input":"2025-12-18T13:07:43.226984Z","iopub.status.idle":"2025-12-18T13:07:43.244187Z","shell.execute_reply.started":"2025-12-18T13:07:43.226967Z","shell.execute_reply":"2025-12-18T13:07:43.243515Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Base","metadata":{}},{"cell_type":"code","source":"class LayerNormProxy3d(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.norm = nn.LayerNorm(dim) #LayerNorm chuẩn hóa chiều cuối cùng\n\n    def forward(self, x):\n        x = einops.rearrange(x, 'b c d h w -> b d h w c')\n        x = self.norm(x)\n        return einops.rearrange(x, 'b d h w c -> b c d h w')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:43.244932Z","iopub.execute_input":"2025-12-18T13:07:43.245149Z","iopub.status.idle":"2025-12-18T13:07:43.261818Z","shell.execute_reply.started":"2025-12-18T13:07:43.245132Z","shell.execute_reply":"2025-12-18T13:07:43.261113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    \"\"\"(Conv3D -> BN -> ReLU) * 2\"\"\"\n    def __init__(self, in_channels, out_channels, num_groups=16, kernel_size=3, padding=1, stride=1, bias=True):\n        super().__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride, bias=bias),\n            nn.GroupNorm(num_groups = num_groups, num_channels = out_channels),\n            nn.LeakyReLU(inplace=True),\n            nn.Conv3d(out_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride, bias=bias),\n            nn.GroupNorm(num_groups = num_groups, num_channels = out_channels),\n            nn.LeakyReLU(inplace=True)\n        )\n    \n    def forward(self, x):\n        return self.double_conv(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:43.263244Z","iopub.execute_input":"2025-12-18T13:07:43.263425Z","iopub.status.idle":"2025-12-18T13:07:43.279401Z","shell.execute_reply.started":"2025-12-18T13:07:43.263410Z","shell.execute_reply":"2025-12-18T13:07:43.278884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ProjectExciteLayer(nn.Module):\n    \"\"\"\n    Project & Excite Module, with wave-modulated and adaptively weighted\n    combination of spatially-squeezed features.\n    \"\"\"\n\n    def __init__(self, num_channels, reduction_ratio=2, mlp_hidden_ratio=1):\n        \"\"\"\n        :param num_channels: No of input channels\n        :param reduction_ratio: By how much num_channels should be reduced for the excitation bottleneck\n        :param mlp_hidden_ratio: Ratio for hidden dim in MLPs generating theta and mixing weights\n        \"\"\"\n        super(ProjectExciteLayer, self).__init__()\n        self.num_channels = num_channels\n        num_channels_reduced = num_channels // reduction_ratio\n        mlp_hidden_dim = num_channels * mlp_hidden_ratio\n\n        # --- MLPs for Theta and Mixing Weights ---\n        # These will operate on a global context vector derived from the input\n\n        # MLP to generate theta parameters for wave modulation (shared for w, h, d)\n        # Outputs C parameters, which will be broadcasted\n        self.theta_mlp = nn.Sequential(\n            nn.Linear(num_channels, mlp_hidden_dim),\n            nn.LayerNorm(mlp_hidden_dim), # Common practice in \"wave\" examples\n            nn.GELU(),\n            nn.Linear(mlp_hidden_dim, num_channels)\n        )\n\n        # MLP to generate mixing weights for the three directions (w, h, d)\n        # Outputs 3*C parameters for per-channel weighting of each direction\n        self.reweight_mlp = nn.Sequential(\n            nn.Linear(num_channels, mlp_hidden_dim),\n            nn.LayerNorm(mlp_hidden_dim), # Common practice in \"wave\" examples\n            nn.GELU(),\n            nn.Linear(mlp_hidden_dim, num_channels * 3) # 3 weights per channel\n        )\n\n        # --- Original P&E Components ---\n        self.relu = nn.ReLU()\n        self.conv_c = nn.Conv3d(in_channels=num_channels, out_channels=num_channels_reduced, kernel_size=1, stride=1)\n        self.conv_cT = nn.Conv3d(in_channels=num_channels_reduced, out_channels=num_channels, kernel_size=1, stride=1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, input_tensor):\n        \"\"\"\n        :param input_tensor: X, shape = (batch_size, num_channels, D, H, W)\n        :return: output tensor\n        \"\"\"\n        batch_size, num_channels, D, H, W = input_tensor.size()\n\n        # --- 1. Original Squeeze Operations ---\n        squeeze_tensor_w = F.adaptive_avg_pool3d(input_tensor, (1, 1, W)) # (B, C, 1, 1, W)\n        squeeze_tensor_h = F.adaptive_avg_pool3d(input_tensor, (1, H, 1)) # (B, C, 1, H, 1)\n        squeeze_tensor_d = F.adaptive_avg_pool3d(input_tensor, (D, 1, 1)) # (B, C, D, 1, 1)\n\n        # --- 2. Generate Global Context for MLPs ---\n        global_context = F.adaptive_avg_pool3d(input_tensor, (1, 1, 1)).view(batch_size, num_channels) # (B, C)\n\n        # --- 3. Generate Theta for Wave Modulation ---\n        # Theta has shape (B, C), will be reshaped for broadcasting with squeezed tensors\n        theta = self.theta_mlp(global_context) # (B, C)\n        # Reshape theta for broadcasting with (B, C, D, H, W) style features\n        theta_bc111 = theta.view(batch_size, num_channels, 1, 1, 1)\n\n        # --- 4. Apply Wave Modulation to Squeezed Tensors ---\n        # s_mod = s * cos(theta) + s * sin(theta)\n        # theta_bc111 will broadcast correctly with squeeze_tensor_w, _h, _d\n        s_w_mod = squeeze_tensor_w * torch.cos(theta_bc111) + squeeze_tensor_w * torch.sin(theta_bc111)\n        s_h_mod = squeeze_tensor_h * torch.cos(theta_bc111) + squeeze_tensor_h * torch.sin(theta_bc111)\n        s_d_mod = squeeze_tensor_d * torch.cos(theta_bc111) + squeeze_tensor_d * torch.sin(theta_bc111)\n\n        # --- 5. Generate Adaptive Mixing Weights ---\n        # reweight_mlp outputs (B, 3*C) for per-channel weights for 3 directions\n        mixing_weights_flat = self.reweight_mlp(global_context) # (B, 3*C)\n        # Reshape to (B, C, 3) and apply softmax over the 3 directions for each channel\n        mixing_weights_per_channel = mixing_weights_flat.view(batch_size, num_channels, 3).softmax(dim=2) # (B, C, 3)\n\n        alpha_w = mixing_weights_per_channel[:, :, 0].view(batch_size, num_channels, 1, 1, 1) # (B, C, 1, 1, 1)\n        alpha_h = mixing_weights_per_channel[:, :, 1].view(batch_size, num_channels, 1, 1, 1) # (B, C, 1, 1, 1)\n        alpha_d = mixing_weights_per_channel[:, :, 2].view(batch_size, num_channels, 1, 1, 1) # (B, C, 1, 1, 1)\n\n        # --- 6. Wave-Modulated and Weighted Combination ---\n        # Each alpha (B,C,1,1,1) will multiply its corresponding modulated squeezed tensor (B,C,D',H',W')\n        final_squeeze_tensor = (alpha_w * s_w_mod.view(batch_size, num_channels, 1, 1, W) +\n                                alpha_h * s_h_mod.view(batch_size, num_channels, 1, H, 1) +\n                                alpha_d * s_d_mod.view(batch_size, num_channels, D, 1, 1))\n        # The .view() calls ensure the components are structured as in the original P&E's sum,\n        # which is important for how self.conv_c processes them.\n\n        # --- 7. Original Excitation Path ---\n        excitation = self.sigmoid(self.conv_cT(self.relu(self.conv_c(final_squeeze_tensor))))\n\n        # --- 8. Apply Excitation ---\n        output_tensor = torch.mul(input_tensor, excitation)\n\n        return output_tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:43.280061Z","iopub.execute_input":"2025-12-18T13:07:43.280294Z","iopub.status.idle":"2025-12-18T13:07:43.296367Z","shell.execute_reply.started":"2025-12-18T13:07:43.280271Z","shell.execute_reply":"2025-12-18T13:07:43.295734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LKA(nn.Module):\n    def __init__(self, dim, k_size):\n        super().__init__()\n        self.k_size = k_size\n        \n        self.conv_w = nn.Conv3d(dim, dim, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2), groups=dim)   \n        self.gn = nn.GroupNorm(num_groups=dim, num_channels=dim)\n        self.irelu = nn.ReLU(inplace=True)\n        self.conv_spatial = nn.Conv3d(dim, dim, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(9, 9, 9), groups=dim, dilation=(3, 3, 3))\n        self.conv = nn.Conv3d(dim, dim, kernel_size=1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        u = x.clone()\n\n        attn = self.conv_w(x)\n\n        attn = self.gn(attn)\n\n        attn = self.irelu(attn)\n\n        attn = self.conv_spatial(attn)\n\n        attn = self.conv(attn)\n\n        attn = self.sigmoid(attn)\n\n        attn = u*attn\n        u = u + attn\n        return u","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:43.297079Z","iopub.execute_input":"2025-12-18T13:07:43.297356Z","iopub.status.idle":"2025-12-18T13:07:43.315331Z","shell.execute_reply.started":"2025-12-18T13:07:43.297333Z","shell.execute_reply":"2025-12-18T13:07:43.314600Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Down2(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.encode1 = nn.Sequential(\n            nn.MaxPool3d(kernel_size=2, stride=2),\n            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False),\n            nn.InstanceNorm3d(num_features=out_channels),\n            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n        )\n        self.spatial_gating_unit = LKA(dim = out_channels, k_size=3)\n        self.conv = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False)\n        self.INorm = nn.InstanceNorm3d(num_features=in_channels)\n        self.LR = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n        self.PE = ProjectExciteLayer(num_channels = out_channels)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        x = self.encode1(x)\n        x = self.spatial_gating_unit(x)\n        x1 = self.INorm(x)\n        x1 = self.PE(x1)\n        x1 = self.sigmoid(x1)\n        x = x1 * x # element-wise multiplied\n        return x\n\n\nclass Down2W(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.wave_pool = WavePool3D(in_channels)\n        self.conv = nn.Sequential(\n            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False),\n            nn.InstanceNorm3d(num_features=out_channels),\n            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n        )\n        self.wavelet_fusion = WaveletAttentionFusion(in_channels, out_channels)\n        self.spatial_gating_unit = LKA(dim=out_channels, k_size=3)\n        self.INorm = nn.InstanceNorm3d(num_features=out_channels)\n        self.PE = ProjectExciteLayer(num_channels=out_channels)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        subbands = self.wave_pool(x)\n        LLL = subbands[0]\n        high_freq = subbands[1:]\n        x_main = self.conv(LLL)\n        x = self.wavelet_fusion(x_main, high_freq)\n        x = self.spatial_gating_unit(x)\n        x1 = self.INorm(x)\n        x1 = self.PE(x1)\n        x1 = self.sigmoid(x1)\n        x = x1 * x\n        return x, subbands","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:43.316026Z","iopub.execute_input":"2025-12-18T13:07:43.316198Z","iopub.status.idle":"2025-12-18T13:07:43.329055Z","shell.execute_reply.started":"2025-12-18T13:07:43.316184Z","shell.execute_reply":"2025-12-18T13:07:43.328455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Up1W(nn.Module):\n    def __init__(self, in_channels, out_channels, trilinear=False):\n        super().__init__()\n        self.upT = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n        self.wave_unpool = WaveUnpool3D(out_channels, option_unpool='cat')\n        \n        self.wavelet_proj = nn.Sequential(\n            nn.Conv3d(out_channels * 7, out_channels, kernel_size=1, \n                      groups=out_channels, bias=False),\n            nn.InstanceNorm3d(out_channels),\n            nn.LeakyReLU(inplace=True)\n        )\n        \n        # Simplified three-way fusion attention\n        self.fusion_attention = nn.Sequential(\n            nn.Conv3d(out_channels * 3, out_channels, kernel_size=1),\n            nn.InstanceNorm3d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv3d(out_channels, 3, kernel_size=1),\n            nn.Sigmoid()\n        )\n        \n        self.conv_out = nn.Sequential(\n            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1,bias=False), \n            nn.InstanceNorm3d(out_channels),\n            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n            \n            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.InstanceNorm3d(out_channels),\n            nn.LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n        \n        self.PE = ProjectExciteLayer(num_channels=out_channels)\n\n    def forward(self, x1, x2, subbands):\n        # Upsample and reconstruct\n        up1 = self.upT(x1)\n        wave_up = self.wave_unpool(subbands, include_low=False)\n        wave_up = self.wavelet_proj(wave_up)\n        \n        # Three-way attention fusion\n        fusion_input = torch.cat([up1, x2, wave_up], dim=1)\n        attention_weights = self.fusion_attention(fusion_input)  # [B, 3, D, H, W]\n        \n        # Weighted fusion\n        fused = (attention_weights[:, 0:1] * up1 + \n                attention_weights[:, 1:2] * x2 + \n                attention_weights[:, 2:3] * wave_up)\n        \n        # Apply PE enhancement and final processing\n        pe_weights = torch.sigmoid(self.PE(fused))\n        enhanced = fused * pe_weights\n        \n        # Final convolutions with residual\n        output = self.conv_out(enhanced)\n        return output + enhanced","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:43.329704Z","iopub.execute_input":"2025-12-18T13:07:43.329954Z","iopub.status.idle":"2025-12-18T13:07:43.347892Z","shell.execute_reply.started":"2025-12-18T13:07:43.329938Z","shell.execute_reply":"2025-12-18T13:07:43.347265Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Wave Block","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom timm.models.layers import DropPath, trunc_normal_\nimport math\n\nclass Mlp3D(nn.Module):\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.act = act_layer()\n        self.drop = nn.Dropout(drop)\n        self.fc1 = nn.Conv3d(in_features, hidden_features, 1, 1)\n        self.fc2 = nn.Conv3d(hidden_features, out_features, 1, 1)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\nclass PATM3D(nn.Module):\n    def __init__(self, in_dim, out_dim, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., mode='fc'):\n        super().__init__()\n        self.in_dim = in_dim\n        self.out_dim = out_dim\n        self.fc_h = nn.Conv3d(in_dim, out_dim, 1, 1, bias=qkv_bias)\n        self.fc_w = nn.Conv3d(in_dim, out_dim, 1, 1, bias=qkv_bias)\n        self.fc_d = nn.Conv3d(in_dim, out_dim, 1, 1, bias=qkv_bias)\n        self.fc_c = nn.Conv3d(in_dim, out_dim, 1, 1, bias=qkv_bias)\n        self.tfc_h = nn.Conv3d(2 * out_dim, out_dim, (1, 1, 7), stride=1, padding=(0, 0, 7//2), groups=out_dim, bias=False)\n        self.tfc_w = nn.Conv3d(2 * out_dim, out_dim, (1, 7, 1), stride=1, padding=(0, 7//2, 0), groups=out_dim, bias=False)\n        self.tfc_d = nn.Conv3d(2 * out_dim, out_dim, (7, 1, 1), stride=1, padding=(7//2, 0, 0), groups=out_dim, bias=False)\n        self.reweight = Mlp3D(out_dim, out_dim // 4, out_dim * 4)\n        self.proj = nn.Conv3d(out_dim, out_dim, 1, 1, bias=True)\n        self.proj_drop = nn.Dropout(proj_drop)\n        self.mode = mode\n        if mode == 'fc':\n            self.theta_h_conv = nn.Sequential(\n                nn.Conv3d(in_dim, out_dim, 1, 1, bias=True),\n                nn.GroupNorm(num_groups=out_dim, num_channels=out_dim),\n                nn.ReLU()\n            )\n            self.theta_w_conv = nn.Sequential(\n                nn.Conv3d(in_dim, out_dim, 1, 1, bias=True),\n                nn.GroupNorm(num_groups=out_dim, num_channels=out_dim),\n                nn.ReLU()\n            )\n            self.theta_d_conv = nn.Sequential(\n                nn.Conv3d(in_dim, out_dim, 1, 1, bias=True),\n                nn.GroupNorm(num_groups=out_dim, num_channels=out_dim),\n                nn.ReLU()\n            )\n        else:\n            self.theta_h_conv = nn.Sequential(\n                nn.Conv3d(in_dim, out_dim, 3, stride=1, padding=1, groups=in_dim, bias=False),\n                nn.GroupNorm(num_groups=out_dim, num_channels=out_dim),\n                nn.ReLU()\n            )\n            self.theta_w_conv = nn.Sequential(\n                nn.Conv3d(in_dim, out_dim, 3, stride=1, padding=1, groups=in_dim, bias=False),\n                nn.GroupNorm(num_groups=out_dim, num_channels=out_dim),\n                nn.ReLU()\n            )\n            self.theta_d_conv = nn.Sequential(\n                nn.Conv3d(in_dim, out_dim, 3, stride=1, padding=1, groups=in_dim, bias=False),\n                nn.GroupNorm(num_groups=out_dim, num_channels=out_dim),\n                nn.ReLU()\n            )\n\n    def forward(self, x):\n        B, C, D, H, W = x.shape\n        theta_h = self.theta_h_conv(x)\n        theta_w = self.theta_w_conv(x)\n        theta_d = self.theta_d_conv(x)\n        x_h = self.fc_h(x)\n        x_w = self.fc_w(x)\n        x_d = self.fc_d(x)\n        x_h = torch.cat([x_h * torch.cos(theta_h), x_h * torch.sin(theta_h)], dim=1)\n        x_w = torch.cat([x_w * torch.cos(theta_w), x_w * torch.sin(theta_w)], dim=1)\n        x_d = torch.cat([x_d * torch.cos(theta_d), x_d * torch.sin(theta_d)], dim=1)\n        h = self.tfc_h(x_h)\n        w = self.tfc_w(x_w)\n        d = self.tfc_d(x_d)\n        c = self.fc_c(x)\n        a = F.adaptive_avg_pool3d(h + w + d + c, output_size=1)\n        a = self.reweight(a).reshape(B, self.out_dim, 4).permute(2, 0, 1).softmax(dim=0).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n        x = h * a[0] + w * a[1] + d * a[2] + c * a[3]\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n\nclass WaveBlock3D(nn.Module):\n    def __init__(self, in_dim, out_dim, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.GroupNorm, mode='fc'):\n        super().__init__()\n        self.in_dim = in_dim\n        self.out_dim = out_dim\n        if norm_layer == nn.GroupNorm:\n            self.norm1 = norm_layer(num_groups=in_dim, num_channels=in_dim)\n            self.norm2 = norm_layer(num_groups=out_dim, num_channels=out_dim)\n        else:\n            self.norm1 = norm_layer(in_dim)\n            self.norm2 = norm_layer(out_dim)\n        self.attn = PATM3D(in_dim=in_dim, out_dim=out_dim, qkv_bias=qkv_bias, qk_scale=None, attn_drop=attn_drop, mode=mode)\n        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n        mlp_hidden_dim = int(out_dim * mlp_ratio)\n        self.mlp = Mlp3D(in_features=out_dim, hidden_features=mlp_hidden_dim, out_features=out_dim, act_layer=act_layer)\n        # Projection for residual connection if in_dim != out_dim\n        self.residual_proj = nn.Conv3d(in_dim, out_dim, 1, 1) if in_dim != out_dim else nn.Identity()\n    \n    def forward(self, x):\n        x = self.residual_proj(x) + self.drop_path(self.attn(self.norm1(x)))\n        x = x + self.drop_path(self.mlp(self.norm2(x)))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:43.348583Z","iopub.execute_input":"2025-12-18T13:07:43.348789Z","iopub.status.idle":"2025-12-18T13:07:44.194677Z","shell.execute_reply.started":"2025-12-18T13:07:43.348767Z","shell.execute_reply":"2025-12-18T13:07:44.193918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Unet(nn.Module):\n    def __init__(self, in_channels=4, n_channels=64, n_classes=2, drop_path_rate=0.1):\n        super().__init__()\n        self.in_channels = in_channels\n        self.n_classes = n_classes\n        self.n_channels = n_channels\n        \n        self.conv = DoubleConv(in_channels, 4*n_channels)\n        self.enc1 = Down2W(4*n_channels, 6*n_channels)\n        self.enc2 = Down2W(6*n_channels, 8*n_channels)\n        self.enc3 = Down2W(8*n_channels, 12*n_channels)\n        \n        self.wave_enc = WaveBlock3D(\n            in_dim=12*n_channels, out_dim=16*n_channels, mlp_ratio=4., qkv_bias=True,\n            drop=0., attn_drop=0., drop_path=drop_path_rate / 3, norm_layer=nn.GroupNorm, mode='fc'\n        )\n        self.wave_bottleneck = WaveBlock3D(\n            in_dim=16*n_channels, out_dim=32*n_channels, mlp_ratio=4., qkv_bias=True,\n            drop=0., attn_drop=0., drop_path=drop_path_rate / 3, norm_layer=nn.GroupNorm, mode='fc'\n        )\n        self.bottleneck_norm = nn.GroupNorm(num_groups=32*n_channels, num_channels=32*n_channels)\n        self.wave_dec = WaveBlock3D(\n            in_dim=32*n_channels, out_dim=16*n_channels, mlp_ratio=4., qkv_bias=True,\n            drop=0., attn_drop=0., drop_path=drop_path_rate / 3, norm_layer=nn.GroupNorm, mode='fc'\n        )\n        \n        self.dec1 = Up1W(16*n_channels, 8*n_channels)\n        self.dec2 = Up1W(8*n_channels, 6*n_channels)\n        self.dec3 = Up1W(6*n_channels, 4*n_channels)\n        self.out = nn.Conv3d(in_channels=4*n_channels, out_channels=n_classes, kernel_size=1)\n\n    def forward(self, x):\n        x1 = self.conv(x)\n        x2, subbands1 = self.enc1(x1)\n        x3, subbands2 = self.enc2(x2)\n        x4, subbands3 = self.enc3(x3)\n        \n        x4 = self.wave_enc(x4)\n        x5 = self.wave_bottleneck(x4)\n        x5 = self.bottleneck_norm(x5)\n        x5 = self.wave_dec(x5)\n        \n        x_out = self.dec1(x5, x3, subbands3)\n        x_out = self.dec2(x_out, x2, subbands2)\n        x_out = self.dec3(x_out, x1, subbands1)\n        out = self.out(x_out)\n        return out\n\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            trunc_normal_(m.weight, std=.02)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, (nn.GroupNorm, nn.LayerNorm)):\n            nn.init.constant_(m.bias, 0)\n            nn.init.constant_(m.weight, 1.0)\n        elif isinstance(m, nn.Conv3d):\n            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.kernel_size[2] * m.out_channels\n            fan_out //= m.groups\n            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n            if m.bias is not None:\n                m.bias.data.zero_()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:44.195406Z","iopub.execute_input":"2025-12-18T13:07:44.195709Z","iopub.status.idle":"2025-12-18T13:07:44.753275Z","shell.execute_reply.started":"2025-12-18T13:07:44.195689Z","shell.execute_reply":"2025-12-18T13:07:44.752316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Unet(in_channels=4, n_classes=3, n_channels=8).to('cuda')\nprint('Number of network parameters:', sum(param.numel() for param in model.parameters()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:44.754101Z","iopub.execute_input":"2025-12-18T13:07:44.754362Z","iopub.status.idle":"2025-12-18T13:07:44.853190Z","shell.execute_reply.started":"2025-12-18T13:07:44.754337Z","shell.execute_reply":"2025-12-18T13:07:44.852572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:44.853918Z","iopub.execute_input":"2025-12-18T13:07:44.854259Z","iopub.status.idle":"2025-12-18T13:07:44.860625Z","shell.execute_reply.started":"2025-12-18T13:07:44.854233Z","shell.execute_reply":"2025-12-18T13:07:44.860075Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# input = torch.randint(\n#         low=0,\n#         high=255,\n#         size=(1, 4, 128, 128, 128),\n#         dtype=torch.float,\n# )\n# input = input.to(\"cuda\")\n# output = model(input)\n# print(output.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:44.861833Z","iopub.execute_input":"2025-12-18T13:07:44.862266Z","iopub.status.idle":"2025-12-18T13:07:44.873964Z","shell.execute_reply.started":"2025-12-18T13:07:44.862249Z","shell.execute_reply":"2025-12-18T13:07:44.873295Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## For the loss\n\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass FocalTverskyLoss(nn.Module):\n    def __init__(self, alpha=0.7, gamma=0.75, smooth=1e-6):\n        super(FocalTverskyLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.smooth = smooth\n\n    def forward(self, y_pred, y_true):\n        # Apply sigmoid if raw logits\n        y_pred = torch.sigmoid(y_pred)\n\n        # Flatten\n        y_true = y_true.contiguous().view(-1)\n        y_pred = y_pred.contiguous().view(-1)\n\n        # Compute Tversky components\n        TP = (y_true * y_pred).sum()\n        FN = (y_true * (1 - y_pred)).sum()\n        FP = ((1 - y_true) * y_pred).sum()\n\n        tversky = (TP + self.smooth) / (TP + self.alpha * FN + (1 - self.alpha) * FP + self.smooth)\n        focal_tversky = torch.pow((1 - tversky), self.gamma)\n\n        return focal_tversky\n\n\nclass EDiceLoss(nn.Module):\n    \"\"\"Dice loss tailored to Brats need.\n    \"\"\"\n\n    def __init__(self, do_sigmoid=True):\n        super(EDiceLoss, self).__init__()\n        self.do_sigmoid = do_sigmoid\n        self.labels = [\"ET\", \"TC\", \"WT\"]\n        self.device = \"cpu\"\n\n    def binary_dice(self, inputs, targets, label_index, metric_mode=False):\n        smooth = 1e-5\n        if self.do_sigmoid:\n            inputs = torch.sigmoid(inputs)\n\n        if metric_mode:\n            inputs = inputs > 0.5\n            if targets.sum() == 0:\n                print(f\"No {self.labels[label_index]} for this patient\")\n                if inputs.sum() == 0:\n                    return torch.tensor(1., device=\"cuda\")\n                else:\n                    return torch.tensor(0., device=\"cuda\")\n            # Threshold the pred\n        intersection = EDiceLoss.compute_intersection(inputs, targets)\n        if metric_mode:\n            dice = (2 * intersection) / ((inputs.sum() + targets.sum()) * 1.0)\n        else:\n            dice = (2 * intersection + smooth) / (inputs.pow(2).sum() + targets.pow(2).sum() + smooth)\n        if metric_mode:\n            return dice\n        return 1 - dice\n\n    @staticmethod\n    def compute_intersection(inputs, targets):\n        intersection = torch.sum(inputs * targets)\n        return intersection\n\n    def forward(self, inputs, target):\n        dice = 0\n        ce = 0\n        CE_L = torch.nn.BCELoss()\n        for i in range(target.size(1)):\n            dice = dice + self.binary_dice(inputs[:, i, ...], target[:, i, ...], i)\n            ce = ce + CE_L(torch.sigmoid(inputs[:, i, ...]), target[:, i, ...])\n        final_dice = (dice + ce) / target.size(1)\n        return final_dice\n\n    def metric(self, inputs, target):\n        dices = []\n        for j in range(target.size(0)):\n            dice = []\n            for i in range(target.size(1)):\n                dice.append(self.binary_dice(inputs[j, i], target[j, i], i, True))\n            dices.append(dice)\n        return dices\n\n\nclass EDiceLoss_Val(nn.Module):\n    \"\"\"Dice loss tailored to Brats need.\n    \"\"\"\n\n    def __init__(self, do_sigmoid=True):\n        super(EDiceLoss_Val, self).__init__()\n        self.do_sigmoid = do_sigmoid\n        self.labels = [\"ET\", \"TC\", \"WT\"]\n        self.device = \"cpu\"\n\n    def binary_dice(self, inputs, targets, label_index, metric_mode=False):\n        smooth = 1e-5\n        if self.do_sigmoid:\n            inputs = torch.sigmoid(inputs)\n\n        if metric_mode:\n            inputs = inputs > 0.5\n            if targets.sum() == 0:\n                print(f\"No {self.labels[label_index]} for this patient\")\n                if inputs.sum() == 0:\n                    return torch.tensor(1., device=\"cuda\")\n                else:\n                    return torch.tensor(0., device=\"cuda\")\n            # Threshold the pred\n        intersection = EDiceLoss_Val.compute_intersection(inputs, targets)\n        if metric_mode:\n            dice = (2 * intersection) / ((inputs.sum() + targets.sum()) * 1.0)\n        else:\n            dice = (2 * intersection + smooth) / (inputs.pow(2).sum() + targets.pow(2).sum() + smooth)\n        if metric_mode:\n            return dice\n        return 1 - dice\n\n    @staticmethod\n    def compute_intersection(inputs, targets):\n        intersection = torch.sum(inputs * targets)\n        return intersection\n\n    def forward(self, inputs, target):\n        dice = 0\n        for i in range(target.size(1)):\n            dice = dice + self.binary_dice(inputs[:, i, ...], target[:, i, ...], i)\n        final_dice = dice / target.size(1)\n        return final_dice\n\n    def metric(self, inputs, target):\n        dices = []\n        for j in range(target.size(0)):\n            dice = []\n            for i in range(target.size(1)):\n                dice.append(self.binary_dice(inputs[j, i], target[j, i], i, True))\n            dices.append(dice)\n        return dices\n\nclass CombinedLoss(nn.Module):\n    def __init__(self, use_focal_tversky=True):\n        super(CombinedLoss, self).__init__()\n        self.focal_tversky = FocalTverskyLoss()\n        self.dice = EDiceLoss()\n        self.use_focal_tversky = use_focal_tversky\n\n    def forward(self, inputs, targets):\n        loss = self.dice(inputs, targets)\n        if self.use_focal_tversky:\n            loss += self.focal_tversky(inputs, targets)\n        return loss\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value.\"\"\"\n\n    def __init__(self, name, fmt=':f'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n        return fmtstr.format(**self.__dict__)\n\n\nclass ProgressMeter(object):\n    def __init__(self, num_batches, meters, prefix=\"\"):\n        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n        self.meters = meters\n        self.prefix = prefix\n\n    def display(self, batch):\n        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n        entries += [str(meter) for meter in self.meters]\n        print('\\t'.join(entries))\n\n    @staticmethod\n    def _get_batch_fmtstr(num_batches):\n        num_digits = len(str(num_batches // 1))\n        fmt = '{:' + str(num_digits) + 'd}'\n        return '[' + fmt + '/' + fmt.format(num_batches) + ']'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:44.874670Z","iopub.execute_input":"2025-12-18T13:07:44.874891Z","iopub.status.idle":"2025-12-18T13:07:44.897123Z","shell.execute_reply.started":"2025-12-18T13:07:44.874871Z","shell.execute_reply":"2025-12-18T13:07:44.896374Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ===================================================================================================","metadata":{}},{"cell_type":"markdown","source":"### Traing CoT+DA","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nWANDB_KEY = user_secrets.get_secret(\"WANDB_KEY\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\npost_trans = Compose(\n    [EnsureType(), Activations(sigmoid=True), AsDiscrete(argmax=False, threshold=0.5)]\n)\n\npost_sigmoid = Activations(sigmoid=True)\npost_pred = AsDiscrete(argmax=False, threshold=0.5)\nroi = (128, 128, 128) #128, 128, 128\nsw_batch_size = 1\noverlap = 0.5\nVAL_AMP = True\n\nos.environ[\"WANDB_DIR\"] = os.path.abspath(\"/kaggle/working\")\n\nwandb.login(key = WANDB_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:44.897840Z","iopub.execute_input":"2025-12-18T13:07:44.898305Z","iopub.status.idle":"2025-12-18T13:07:50.948515Z","shell.execute_reply.started":"2025-12-18T13:07:44.898282Z","shell.execute_reply":"2025-12-18T13:07:50.947963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#----------------\ndef train_epoch(model, loader, optimizer, epoch, loss_func, end, wandb_tracking = 0):\n    model.train()\n    run_loss = AverageMeter('Loss', ':.4e')\n\n    num_steps = len(loader)\n    print(f\"Epoch {epoch}: Number of steps (batches) in this epoch: {num_steps}\")\n\n    for idx, batch_data in enumerate(loader):\n        torch.cuda.empty_cache()\n        data, target = batch_data[\"image\"].float().cuda(), batch_data[\"label\"].float().cuda()\n        logits = model(data)\n\n        loss = loss_func(logits, target)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        run_loss.update(loss.item(), n=batch_size)\n        if wandb_tracking == 1:\n            wandb.log({\"train_step_loss\": loss.item()})\n\n    # Log the average loss for the epoch\n    if wandb_tracking == 1:\n        wandb.log({\"train_epoch_loss\": run_loss.avg, \"epoch\": epoch})\n    return run_loss.avg\n\n# ===============================================================================================\ndef model_inferer(input, model):\n    def _compute(input):\n        return sliding_window_inference(\n            inputs=input,\n            roi_size= roi,\n            sw_batch_size=sw_batch_size,\n            predictor=model,\n            overlap=overlap,\n        )\n    with torch.no_grad(), torch.amp.autocast(device_type='cuda', enabled=VAL_AMP):\n        output = _compute(input)\n    \n    # Giải phóng bộ nhớ không cần thiết\n    torch.cuda.empty_cache()\n    return output\n\n\n# ===============================================================================================\n\ndef evaluate_model(model, loader, epoch, acc_func, criterian_val, metric, wandb_tracking = 0):\n    model.eval()\n    run_acc = AverageMeter('Loss', ':.4e')\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for idx, batch_data in enumerate(loader):\n            val_inputs, val_labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n\n            logits = model_inferer(val_inputs, model)\n            val_outputs_list = decollate_batch(logits)\n            val_labels_list = decollate_batch(val_labels)\n\n\n            # Ensure all tensors are on the same device\n            val_output_convert = [post_trans(val_pred_tensor).to(device) for val_pred_tensor in val_outputs_list]\n            val_labels_convert = [label.to(device) for label in val_labels_list]\n            del val_inputs, val_labels, logits, val_outputs_list, val_labels_list\n            torch.cuda.empty_cache()\n            all_preds.extend(val_output_convert)\n            all_labels.extend(val_labels_convert)\n\n            # Reset and compute metrics\n            acc_func.reset()\n            acc_func(y_pred=val_output_convert, y=val_labels_convert)\n\n            acc, not_nans = acc_func.aggregate()\n            run_acc.update(acc.cpu().numpy(), n=not_nans.cpu().numpy())\n        \n        dice_et = run_acc.avg[0]\n        dice_tc = run_acc.avg[1]\n        dice_wt = run_acc.avg[2]\n\n    # Log validation metrics\n    if wandb_tracking == 1:\n        wandb.log({\n            \"val_epoch_dice_et\": dice_et,\n            \"val_epoch_dice_tc\": dice_tc,\n            \"val_epoch_dice_wt\": dice_wt,\n            \"epoch\": epoch\n        })\n    return run_acc.avg\n\n# ===============================================================================================\n\n\ndef trainer(model, train_loader, val_loader, optimizer, loss_func, \n            acc_func, criterian_val, metric, scheduler, start_epoch=1, end_epoch=3, save_every=1, checkpoint_path=None, wandb_tracking = 0):\n    # Initialize wandb logging\n    if wandb_tracking:\n        wandb.init(entity=\"huynhtongdangkhoa-vietnam-national-university\", project=\"AblationStudy\", name=\"Baseline_E_seed1\", id=\"19633214152\", resume=\"allow\", config={\n            \"epochs\": end_epoch,\n            \"optimizer\": optimizer.__class__.__name__,\n            \"learning_rate\": optimizer.param_groups[0][\"lr\"],\n            \"loss_func\": loss_func.__class__.__name__,\n            \"scheduler\": scheduler.__class__.__name__ if scheduler else None\n        })\n        wandb_table = wandb.Table(columns=[\"Epoch\", \"Train Loss\", \"Dice_ET\", \"Dice_TC\", \"Dice_WT\", \"Best Model\"])\n        print(\"Wandb ID:\", wandb.run.id)\n        wandb_table = wandb.Table(columns=[\"Epoch\", \"Train Loss\", \"Dice_ET\", \"Dice_TC\", \"Dice_WT\", \"Best Model\"])\n        print(\"Wandb ID:\", wandb.run.id)\n\n    val_acc_max = 0.0\n    best_epoch = 0\n    TC_dices = []\n    WT_dices = []\n    ET_dices = []\n    avg_dices = []\n    loss_epochs, train_epochs = [], []\n\n    # If checkpoint path is provided, load model and optimizer states\n    if checkpoint_path and os.path.exists(checkpoint_path):\n        checkpoint = torch.load(checkpoint_path, weights_only = False)\n        model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n        # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        if scheduler:\n            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        start_epoch = checkpoint['epoch'] + 1  # Start from the next epoch\n        val_acc_max = checkpoint['val_acc_max']  # Retain the best validation accuracy\n\n        print(f\"Resuming training from epoch {start_epoch}...\")\n    \n    for epoch in range(start_epoch, end_epoch + 1):\n        # Train the model for the current epoch\n        train_loss = train_epoch(model, train_loader, optimizer, epoch=epoch, loss_func=loss_func, end=end_epoch, wandb_tracking = wandb_tracking)\n        torch.cuda.empty_cache()\n\n        # Update scheduler if available\n        if scheduler is not None:\n            scheduler.step()\n        \n        # Evaluate the model after every 'save_every' epoch or at the last epoch\n        if epoch % save_every == 0 or epoch == end_epoch or epoch == start_epoch:\n            loss_epochs.append(train_loss)\n            train_epochs.append(epoch)\n\n            val_acc = evaluate_model(model, val_loader, epoch=epoch,\n                                     acc_func=acc_func, criterian_val=criterian_val, metric=metric, wandb_tracking = wandb_tracking)\n            ET_dice = val_acc[0]\n            TC_dice = val_acc[1]\n            WT_dice = val_acc[2]\n            val_avg_acc = np.mean(val_acc)\n\n            # Update dice coefficients\n            ET_dices.append(ET_dice)\n            TC_dices.append(TC_dice)\n            WT_dices.append(WT_dice)\n            avg_dices.append(val_avg_acc)\n\n            # Check if this is the best model\n            best_model_flag = False\n            if val_avg_acc > val_acc_max:\n                print(f\"New best ({val_acc_max:.6f} --> {val_avg_acc:.6f}) at epoch {epoch}\")\n                val_acc_max = val_avg_acc\n                best_epoch = epoch\n                best_model_flag = True\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),  # Save scheduler state\n                'val_acc_max': val_acc_max,\n            }, save_current)  # Save model to 'model.pth'\n\n            if best_model_flag:\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'scheduler_state_dict': scheduler.state_dict(),  # Save scheduler state\n                    'val_acc_max': val_acc_max,\n                }, save_path)  # Save model to 'model.pth'\n                \n\n            torch.cuda.empty_cache()\n\n            # ✅ Add row to wandb table\n            if wandb_tracking == 1:\n                wandb_table.add_data(epoch, train_loss, ET_dice, TC_dice, WT_dice, \"Yes\" if best_model_flag else \"No\")\n\n    # ✅ Log table to wandb\n    if wandb_tracking == 1:\n        wandb.log({\"Training Metrics\": wandb_table})\n\n    return (val_acc_max, TC_dices, WT_dices, ET_dices, avg_dices, loss_epochs, train_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:50.951278Z","iopub.execute_input":"2025-12-18T13:07:50.951891Z","iopub.status.idle":"2025-12-18T13:07:50.971613Z","shell.execute_reply.started":"2025-12-18T13:07:50.951843Z","shell.execute_reply":"2025-12-18T13:07:50.971064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start = 0\nend = 200 #max_epochs\nbatch_size = 1\nsave_every = 5 #\n\nlearning_rate = 1e-4\nweight_decay = 1e-5\ncheckpoint_path = \"/kaggle/input/doublew-hf/pytorch/default/1/DoubleW-hf.pth\"\n###\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\nsave_path = os.path.join(save_dir, \"best_metric_model.pth\")\nsave_current = os.path.join(save_dir, \"current_model.pth\")\n###\n\ncriterion = CombinedLoss().cuda()\ncriterian_val = EDiceLoss_Val().cuda()\nmetric = criterian_val.metric\n\ndice_acc = DiceMetric(include_background=True, reduction='mean_batch', get_not_nans=True)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = end)\n\n\n(val_acc_max, TC_dices, WT_dices, ET_dices, avg_dices, loss_epochs, train_epochs)  = trainer(model = model,\n                                                                                            train_loader = train_loader,\n                                                                                            val_loader = val_loader,\n                                                                                            optimizer = optimizer,\n                                                                                            loss_func = criterion,\n                                                                                            acc_func = dice_acc,\n                                                                                            criterian_val = criterian_val,\n                                                                                            metric = metric,\n                                                                                            scheduler = scheduler,\n                                                                                            start_epoch = start,\n                                                                                            end_epoch = end,\n                                                                                            save_every = save_every,\n                                                                                            checkpoint_path = checkpoint_path,\n                                                                                            wandb_tracking = 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:07:50.972680Z","iopub.execute_input":"2025-12-18T13:07:50.973168Z","execution_failed":"2025-12-18T13:09:41.460Z"}},"outputs":[],"execution_count":null}]}